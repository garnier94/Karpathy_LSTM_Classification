{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,OrdinalEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Char LSTM\n",
    "\n",
    "Objectif : \n",
    "\n",
    "- Apprendre à implémenter un LSTM en pytorch\n",
    "- Utiliser LSTM +DataLoader\n",
    "- Tester la différence entre une validation aléatoire & une validation sur période\n",
    "\n",
    "### I Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat =  open('input.txt', 'r')\n",
    "data = cat.read()\n",
    "data = list(map(ord, data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_encoder = OrdinalEncoder()\n",
    "data = ord_encoder.fit_transform(np.array(data).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/remy/.virtualenvs/pytorch_env/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1115394, 65)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder= OneHotEncoder()\n",
    "encoded_data = encoder.fit_transform(data).todense()\n",
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100000\n",
    "n_valid = 100000\n",
    "n_test = encoded_data.shape[0]-n_train-n_valid\n",
    "\n",
    "n_param = encoded_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II Modèle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paramètres\n",
    "\n",
    "##LSTM\n",
    "input_size = n_param\n",
    "output_size = n_param\n",
    "hidden_size = 512\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "n_histo = 1\n",
    "temperature= 2\n",
    "\n",
    "\n",
    "##Learning\n",
    "learning_rate = 3e-4\n",
    "batch_size = 200\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_size\n",
    "        self.n_histo = n_histo\n",
    "        self.temperature = temperature\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size = hidden_size, num_layers = num_layers, dropout=dropout)\n",
    "\n",
    "        self.hidden_cell = (torch.zeros(num_layers, 1,self.hidden_layer_size).to(device),\n",
    "                            torch.zeros(num_layers, 1 ,self.hidden_layer_size).to(device))\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_layer_size, output_size, bias=False)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        \"\"\"\n",
    "        m = input_seq.shape[0]\n",
    "        l = []\n",
    "        for i in range(0, m-n_histo):\n",
    "            l.append(input_seq[i:i+n_histo,:])\n",
    "        dat = torch.stack(l,1)\n",
    "         \"\"\"\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1,1, n_param), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions /temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM().cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set=  encoded_data[:n_train,:]\n",
    "training_ds = TensorDataset(torch.tensor(training_set[:-1,:], dtype = torch.float32),torch.tensor(data[1:n_train],dtype = torch.int64))\n",
    "training_dl = DataLoader(training_ds,batch_size=batch_size , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set=  encoded_data[n_train:n_train+n_valid,:]\n",
    "X_valid = torch.tensor(valid_set[:-1,:], dtype = torch.float32)\n",
    "y_valid = torch.tensor(data[n_train+n_histo:n_train+n_valid],dtype = torch.int64)[:,0]\n",
    "X_train =  torch.tensor(training_set[:-1,:], dtype = torch.float32)\n",
    "y_train =  torch.tensor(data[n_histo:n_train],dtype = torch.int64)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 4.17312956 Valid loss: 4.17314816\n",
      "epoch:   1 loss: 3.30493188 Valid loss: 3.31528616\n",
      "epoch:   2 loss: 3.30442810 Valid loss: 3.31541514\n",
      "epoch:   3 loss: 3.30400252 Valid loss: 3.31539559\n",
      "epoch:   4 loss: 3.30423808 Valid loss: 3.31575131\n",
      "epoch:   5 loss: 3.30419874 Valid loss: 3.31582165\n",
      "epoch:   6 loss: 3.30389762 Valid loss: 3.31561947\n",
      "epoch:   7 loss: 3.30350089 Valid loss: 3.31504107\n",
      "epoch:   8 loss: 2.66118383 Valid loss: 2.75695515\n",
      "epoch:   9 loss: 2.40609670 Valid loss: 2.54462481\n",
      "epoch:  10 loss: 2.28527522 Valid loss: 2.44916296\n",
      "epoch:  11 loss: 2.18329597 Valid loss: 2.37168121\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    y_pred_train = model(X_train.to(device))\n",
    "    single_loss = loss_function(y_pred_train, y_train.to(device))\n",
    "    y_pred_valid = model(X_valid.to(device))\n",
    "    valid_loss = loss_function(y_pred_valid, y_valid.to(device))\n",
    "    \n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f} Valid loss: {valid_loss.item():10.8f}')\n",
    "    \n",
    "    for seq, labels in training_dl:\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(num_layers,1,model.hidden_layer_size).to(device), torch.zeros(num_layers,1,model.hidden_layer_size).to(device))\n",
    "        y_pred = model(seq.to(device))\n",
    "        single_loss = loss_function(y_pred, labels[:,0].to(device))\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_txt(seq):\n",
    "    cate = ord_encoder.inverse_transform(encoder.inverse_transform(np.array(seq)))\n",
    "    txt = ''.join(list(map(chr,cate)))\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = X_train[-100:]\n",
    "a= decode_txt(seq)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hidden_cell = (torch.zeros(num_layers,1,model.hidden_layer_size).to(device), torch.zeros(num_layers,1,model.hidden_layer_size).to(device))\n",
    "\n",
    "for i in range(400):\n",
    "    next_chr =  model(seq.to(device))\n",
    "    arr = F.softmax(next_chr[-1,:]).detach().cpu().numpy()\n",
    "    i =  np.argmax(arr)\n",
    "    a = torch.zeros(1,65)\n",
    "    a[0,i] = 1\n",
    "    seq = torch.cat([seq, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= decode_txt(seq)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq= seq[-30:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modele using Hold-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
